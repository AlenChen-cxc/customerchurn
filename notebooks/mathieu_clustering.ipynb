{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7717852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1ff18b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3352/2459300368.py:1: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../raw_data/raw_en.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../raw_data/raw_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419f8924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457074, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69719e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14d0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stars(row):\n",
    "    if not pd.isnull(row['stars']):\n",
    "        if row['stars'] > 3:\n",
    "            return 'Recommended'\n",
    "        return 'Not Recommended'\n",
    "    return row['recommendation']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7756c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recommendation'] = df.apply(convert_stars, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da26deb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>review</th>\n",
       "      <th>playing_hours</th>\n",
       "      <th>source</th>\n",
       "      <th>stars</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457024</th>\n",
       "      <td>zhexue-daolun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Inspiring people to think</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457025</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>very useful, very valuable.I had learn so many...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457026</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Great</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457027</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>I love this course and learn a lot from it. St...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457028</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Great course regarding professionalism, it tou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457029</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Wonderful lesson which should be promoted in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457030</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Very useful! I have learned a lot from this co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457031</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>It worth spend your time to study and repeat a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457032</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Nice course focusing on the essentials in work...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457033</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Really enjoy this course,and like the professor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457034</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Learned a lot from it! Appreciated it!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457035</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>No matter you are new to your career or you ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457036</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>I wish I learn the course before graduate and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457037</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Very common part which we normally miss up hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457038</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>略overwhelming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457039</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Very thoughtful.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457040</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>What I can learn from the course are surprised...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457041</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Very helpful and clear! Thanks for the class!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457042</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Highly recommended!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457043</th>\n",
       "      <td>zhichang-suyang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>really good and useful course</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457044</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Extremely informative course though the Englis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457045</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>I love this course because it gives a basic kn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457046</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>very interesting course！！！</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457047</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>A wonderful course. I totally enjoyed it and h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457048</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>good course but not fully completed. Learned a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>3.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457049</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Good for understanding the philosophy of Chine...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457050</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Very good teacher, explicit explanations.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457051</th>\n",
       "      <td>zhong-yao-zhi-shi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>A good way to learn chinese culture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457052</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>How I can continue the course, there is no sub...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457053</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>Sadly, there only english subtitles in the fir...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457054</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>I learned a lot about the principles of Buddhi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457055</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Very Informative and Systematic course. From r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457056</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>I am a student of Western Medicine，more and mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457057</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>It said it was subtitled into English but that...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457058</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>ONly in chinese. Not English subtitles.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457059</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>Need more (understandable) subtitles. Peer-rev...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457060</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>I have learned lots of Chinese tradition.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457061</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>The instructor looks nerves when he talking.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457062</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Very good course. By a stroke of luck, before ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457063</th>\n",
       "      <td>zhong-yi-yao-wen-hua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>This course explains the cultural of Tradition...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457064</th>\n",
       "      <td>zhongguorenwenjingdiandaodu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>The lecturer picked the most famous authors fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457065</th>\n",
       "      <td>zhuangzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>Please be advised that this course is not stru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457066</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Recommended</td>\n",
       "      <td>For those interested in taking exams, these qu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>2.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457067</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>This course is awesome. It introduce the Zika ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457068</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Great, clear, concise, explanations on everyth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457069</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Trendy topic with talks from expertises in the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457070</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>Wonderful! Simple and clear language, good ins...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457071</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>an interesting and fun course. thanks. dr quincy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>5.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457072</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>very broad perspective, up to date information...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457073</th>\n",
       "      <td>zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>An informative course on the social and financ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coursera</td>\n",
       "      <td>4.0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name date   recommendation  \\\n",
       "457024                zhexue-daolun  NaN      Recommended   \n",
       "457025              zhichang-suyang  NaN      Recommended   \n",
       "457026              zhichang-suyang  NaN      Recommended   \n",
       "457027              zhichang-suyang  NaN      Recommended   \n",
       "457028              zhichang-suyang  NaN      Recommended   \n",
       "457029              zhichang-suyang  NaN      Recommended   \n",
       "457030              zhichang-suyang  NaN      Recommended   \n",
       "457031              zhichang-suyang  NaN      Recommended   \n",
       "457032              zhichang-suyang  NaN      Recommended   \n",
       "457033              zhichang-suyang  NaN      Recommended   \n",
       "457034              zhichang-suyang  NaN      Recommended   \n",
       "457035              zhichang-suyang  NaN      Recommended   \n",
       "457036              zhichang-suyang  NaN      Recommended   \n",
       "457037              zhichang-suyang  NaN      Recommended   \n",
       "457038              zhichang-suyang  NaN      Recommended   \n",
       "457039              zhichang-suyang  NaN      Recommended   \n",
       "457040              zhichang-suyang  NaN      Recommended   \n",
       "457041              zhichang-suyang  NaN      Recommended   \n",
       "457042              zhichang-suyang  NaN      Recommended   \n",
       "457043              zhichang-suyang  NaN      Recommended   \n",
       "457044            zhong-yao-zhi-shi  NaN      Recommended   \n",
       "457045            zhong-yao-zhi-shi  NaN      Recommended   \n",
       "457046            zhong-yao-zhi-shi  NaN      Recommended   \n",
       "457047            zhong-yao-zhi-shi  NaN      Recommended   \n",
       "457048            zhong-yao-zhi-shi  NaN  Not Recommended   \n",
       "457049            zhong-yao-zhi-shi  NaN      Recommended   \n",
       "457050            zhong-yao-zhi-shi  NaN      Recommended   \n",
       "457051            zhong-yao-zhi-shi  NaN      Recommended   \n",
       "457052         zhong-yi-yao-wen-hua  NaN      Recommended   \n",
       "457053         zhong-yi-yao-wen-hua  NaN  Not Recommended   \n",
       "457054         zhong-yi-yao-wen-hua  NaN      Recommended   \n",
       "457055         zhong-yi-yao-wen-hua  NaN      Recommended   \n",
       "457056         zhong-yi-yao-wen-hua  NaN      Recommended   \n",
       "457057         zhong-yi-yao-wen-hua  NaN  Not Recommended   \n",
       "457058         zhong-yi-yao-wen-hua  NaN  Not Recommended   \n",
       "457059         zhong-yi-yao-wen-hua  NaN  Not Recommended   \n",
       "457060         zhong-yi-yao-wen-hua  NaN      Recommended   \n",
       "457061         zhong-yi-yao-wen-hua  NaN  Not Recommended   \n",
       "457062         zhong-yi-yao-wen-hua  NaN      Recommended   \n",
       "457063         zhong-yi-yao-wen-hua  NaN      Recommended   \n",
       "457064  zhongguorenwenjingdiandaodu  NaN      Recommended   \n",
       "457065                     zhuangzi  NaN  Not Recommended   \n",
       "457066                         zika  NaN  Not Recommended   \n",
       "457067                         zika  NaN      Recommended   \n",
       "457068                         zika  NaN      Recommended   \n",
       "457069                         zika  NaN      Recommended   \n",
       "457070                         zika  NaN      Recommended   \n",
       "457071                         zika  NaN      Recommended   \n",
       "457072                         zika  NaN      Recommended   \n",
       "457073                         zika  NaN      Recommended   \n",
       "\n",
       "                                                   review  playing_hours  \\\n",
       "457024                          Inspiring people to think            NaN   \n",
       "457025  very useful, very valuable.I had learn so many...            NaN   \n",
       "457026                                              Great            NaN   \n",
       "457027  I love this course and learn a lot from it. St...            NaN   \n",
       "457028  Great course regarding professionalism, it tou...            NaN   \n",
       "457029  Wonderful lesson which should be promoted in a...            NaN   \n",
       "457030  Very useful! I have learned a lot from this co...            NaN   \n",
       "457031  It worth spend your time to study and repeat a...            NaN   \n",
       "457032  Nice course focusing on the essentials in work...            NaN   \n",
       "457033   Really enjoy this course,and like the professor.            NaN   \n",
       "457034             Learned a lot from it! Appreciated it!            NaN   \n",
       "457035  No matter you are new to your career or you ar...            NaN   \n",
       "457036  I wish I learn the course before graduate and ...            NaN   \n",
       "457037  Very common part which we normally miss up hav...            NaN   \n",
       "457038                                      略overwhelming            NaN   \n",
       "457039                                   Very thoughtful.            NaN   \n",
       "457040  What I can learn from the course are surprised...            NaN   \n",
       "457041      Very helpful and clear! Thanks for the class!            NaN   \n",
       "457042                                Highly recommended!            NaN   \n",
       "457043                      really good and useful course            NaN   \n",
       "457044  Extremely informative course though the Englis...            NaN   \n",
       "457045  I love this course because it gives a basic kn...            NaN   \n",
       "457046                         very interesting course！！！            NaN   \n",
       "457047  A wonderful course. I totally enjoyed it and h...            NaN   \n",
       "457048  good course but not fully completed. Learned a...            NaN   \n",
       "457049  Good for understanding the philosophy of Chine...            NaN   \n",
       "457050          Very good teacher, explicit explanations.            NaN   \n",
       "457051                A good way to learn chinese culture            NaN   \n",
       "457052  How I can continue the course, there is no sub...            NaN   \n",
       "457053  Sadly, there only english subtitles in the fir...            NaN   \n",
       "457054  I learned a lot about the principles of Buddhi...            NaN   \n",
       "457055  Very Informative and Systematic course. From r...            NaN   \n",
       "457056  I am a student of Western Medicine，more and mo...            NaN   \n",
       "457057  It said it was subtitled into English but that...            NaN   \n",
       "457058            ONly in chinese. Not English subtitles.            NaN   \n",
       "457059  Need more (understandable) subtitles. Peer-rev...            NaN   \n",
       "457060          I have learned lots of Chinese tradition.            NaN   \n",
       "457061       The instructor looks nerves when he talking.            NaN   \n",
       "457062  Very good course. By a stroke of luck, before ...            NaN   \n",
       "457063  This course explains the cultural of Tradition...            NaN   \n",
       "457064  The lecturer picked the most famous authors fr...            NaN   \n",
       "457065  Please be advised that this course is not stru...            NaN   \n",
       "457066  For those interested in taking exams, these qu...            NaN   \n",
       "457067  This course is awesome. It introduce the Zika ...            NaN   \n",
       "457068  Great, clear, concise, explanations on everyth...            NaN   \n",
       "457069  Trendy topic with talks from expertises in the...            NaN   \n",
       "457070  Wonderful! Simple and clear language, good ins...            NaN   \n",
       "457071   an interesting and fun course. thanks. dr quincy            NaN   \n",
       "457072  very broad perspective, up to date information...            NaN   \n",
       "457073  An informative course on the social and financ...            NaN   \n",
       "\n",
       "          source  stars language  \n",
       "457024  coursera    5.0       en  \n",
       "457025  coursera    5.0       en  \n",
       "457026  coursera    5.0       en  \n",
       "457027  coursera    5.0       en  \n",
       "457028  coursera    5.0       en  \n",
       "457029  coursera    5.0       en  \n",
       "457030  coursera    5.0       en  \n",
       "457031  coursera    5.0       en  \n",
       "457032  coursera    4.0       en  \n",
       "457033  coursera    5.0       en  \n",
       "457034  coursera    5.0       en  \n",
       "457035  coursera    5.0       en  \n",
       "457036  coursera    5.0       en  \n",
       "457037  coursera    4.0       en  \n",
       "457038  coursera    4.0       en  \n",
       "457039  coursera    5.0       en  \n",
       "457040  coursera    5.0       en  \n",
       "457041  coursera    5.0       en  \n",
       "457042  coursera    5.0       en  \n",
       "457043  coursera    5.0       en  \n",
       "457044  coursera    4.0       en  \n",
       "457045  coursera    5.0       en  \n",
       "457046  coursera    5.0       en  \n",
       "457047  coursera    5.0       en  \n",
       "457048  coursera    3.0       en  \n",
       "457049  coursera    5.0       en  \n",
       "457050  coursera    5.0       en  \n",
       "457051  coursera    5.0       en  \n",
       "457052  coursera    5.0       en  \n",
       "457053  coursera    1.0       en  \n",
       "457054  coursera    5.0       en  \n",
       "457055  coursera    5.0       en  \n",
       "457056  coursera    5.0       en  \n",
       "457057  coursera    1.0       en  \n",
       "457058  coursera    1.0       en  \n",
       "457059  coursera    1.0       en  \n",
       "457060  coursera    4.0       en  \n",
       "457061  coursera    1.0       en  \n",
       "457062  coursera    4.0       en  \n",
       "457063  coursera    5.0       en  \n",
       "457064  coursera    5.0       en  \n",
       "457065  coursera    1.0       en  \n",
       "457066  coursera    2.0       en  \n",
       "457067  coursera    5.0       en  \n",
       "457068  coursera    5.0       en  \n",
       "457069  coursera    4.0       en  \n",
       "457070  coursera    5.0       en  \n",
       "457071  coursera    5.0       en  \n",
       "457072  coursera    4.0       en  \n",
       "457073  coursera    4.0       en  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b621e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_recommended = df[df['recommendation'] == 'Not Recommended']\n",
    "from gensim.models import Word2Vec\n",
    "X_train = df_not_recommended.head(10000)['review']\n",
    "X_test = df_not_recommended.tail(1000)['review']\n",
    "word2vec = Word2Vec(sentences=X_train, vector_size = 100, min_count = 10, window = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dadd2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12       Amount of bugs and glitches from error during ...\n",
       "19       i would not recommend this.. this game used to...\n",
       "26       I couldn't even start a gamewith My friends. O...\n",
       "27       The game is completely unbalanced it doesn't m...\n",
       "33                                  this game is dog s hit\n",
       "                               ...                        \n",
       "50210    Constantly crashes on a high end terminal. Res...\n",
       "50211                              How much money you got?\n",
       "50212                                 Physics are crap lol\n",
       "50217    Honestly when i started this game it was fun a...\n",
       "50237                               can i refund this game\n",
       "Name: review, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60c6602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed = embedding(word2vec, X_train)\n",
    "X_test_embed = embedding(word2vec, X_test)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post', maxlen=200)\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cf1ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5668197e-01, -1.0035462e-01, -7.3657125e-02, -4.7607812e-01,\n",
       "        4.3416411e-01,  9.6091464e-02,  2.1099460e-01, -1.0169571e-01,\n",
       "       -6.3002992e-01,  2.5718528e-01, -5.5816054e-01,  3.0465093e-02,\n",
       "       -5.3394186e-01, -2.9645509e-01,  5.7352994e-02,  1.9006287e-01,\n",
       "        4.1985801e-01, -5.8668238e-01,  1.2117300e-01,  3.8626063e-01,\n",
       "       -8.7962314e-02,  5.1249176e-02,  8.9103359e-01,  6.8837488e-01,\n",
       "       -2.7915746e-01,  2.2496128e-01,  1.5336223e-01,  1.1644909e-01,\n",
       "        2.7969062e-01,  2.0238650e-01,  4.8326176e-01, -1.3670628e-01,\n",
       "       -7.6164287e-01,  1.4544466e-04, -3.4322169e-01,  4.8545852e-01,\n",
       "        4.3954480e-02, -3.9781552e-02, -2.3314089e-02, -2.6607072e-01,\n",
       "        3.9634485e-02,  2.0401867e-01,  2.1212146e-01,  9.6161207e-03,\n",
       "       -2.1691270e-01,  4.2891812e-01, -1.5417603e-01, -2.8370976e-01,\n",
       "       -4.3403739e-01,  4.6387957e-03, -2.2318797e-01, -5.4910207e-01,\n",
       "       -2.8513557e-01, -2.2320358e-01,  1.8185526e-01, -5.1167774e-01,\n",
       "        5.8275849e-01,  3.9611837e-01, -2.2383030e-01, -5.1905370e-01,\n",
       "       -1.1624854e-01,  1.2382611e-01,  2.0795821e-01,  7.3127434e-02,\n",
       "       -3.6722824e-02, -1.4244913e-01,  7.2411798e-02,  5.8405817e-01,\n",
       "       -3.8921397e-02,  4.9069995e-01,  3.6476871e-01,  7.5457925e-01,\n",
       "       -2.9549912e-02, -1.4273153e-01,  3.5665640e-01, -8.6250424e-02,\n",
       "       -2.7068129e-01,  2.8859720e-01, -1.2746318e-01, -3.0251390e-01,\n",
       "       -2.2990108e-01,  8.9488663e-02,  2.4280211e-01,  1.6588286e-01,\n",
       "        6.5109462e-01, -3.4405604e-01, -2.6310357e-01, -3.0239010e-01,\n",
       "       -6.9084376e-01, -6.9984490e-01,  2.7741703e-01, -5.9548002e-01,\n",
       "        6.1479498e-02, -6.5177697e-01, -3.6719128e-02,  9.5603183e-02,\n",
       "        1.3902332e-01, -5.6769538e-01,  2.6751626e-01,  2.2239838e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee262730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import  Dense, Masking, LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "def build_encoder(latent_dimension):\n",
    "    '''returns an encoder model, of output_shape equals to latent_dimension'''\n",
    "    encoder = Sequential()\n",
    "    \n",
    "    encoder.add(Masking(mask_value=0))\n",
    "    encoder.add(LSTM(latent_dimension, activation=\"tanh\"))\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc2272b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "encoder = build_encoder(2)\n",
    "#encoder.build((None,200,100))\n",
    "#encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06d30a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(latent_dimension):\n",
    "    # $CHALLENGIFY_BEGIN\n",
    "    decoder = Sequential()\n",
    "    decoder.add(RepeatVector(200)) #RepeatVector add comments\n",
    "    decoder.add(LSTM(100, activation='tanh', return_sequences=True))\n",
    "    decoder.add(TimeDistributed(Dense(100))) #TimeDistrivuted add comments\n",
    "\n",
    "    return decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8523aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = build_decoder(2)\n",
    "# decoder.build((None,200,100))\n",
    "# decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "398b27d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a27ca918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "def build_autoencoder(encoder, decoder):\n",
    "    inp = Input(X_train_pad.shape[1:])\n",
    "    encoded = encoder(inp)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = Model(inp, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90abc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = build_autoencoder(encoder, decoder)\n",
    "#autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae95c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c733fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cc08acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 153s 487ms/step - loss: 0.1002\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 135s 432ms/step - loss: 0.1002\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 143s 457ms/step - loss: 0.1000\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 142s 454ms/step - loss: 0.0997\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 149s 476ms/step - loss: 0.0982\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 135s 431ms/step - loss: 0.0965\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 135s 431ms/step - loss: 0.0957\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 138s 439ms/step - loss: 0.0953\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 134s 428ms/step - loss: 0.0949\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 134s 427ms/step - loss: 0.0946\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 137s 438ms/step - loss: 0.0944\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 140s 446ms/step - loss: 0.0943\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 137s 439ms/step - loss: 0.0943\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 138s 441ms/step - loss: 0.0942\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 154s 493ms/step - loss: 0.0940\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 160s 511ms/step - loss: 0.0940\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 152s 484ms/step - loss: 0.0939\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 144s 460ms/step - loss: 0.0938\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 139s 443ms/step - loss: 0.0938\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 131s 419ms/step - loss: 0.0937\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 129s 412ms/step - loss: 0.0937\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 130s 414ms/step - loss: 0.0938\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 127s 406ms/step - loss: 0.0937\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 123s 394ms/step - loss: 0.0936\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 131s 417ms/step - loss: 0.0936\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 126s 401ms/step - loss: 0.0935\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 127s 407ms/step - loss: 0.0936\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 127s 406ms/step - loss: 0.0935\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 124s 397ms/step - loss: 0.0933\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 127s 405ms/step - loss: 0.0936\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.0934\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 126s 403ms/step - loss: 0.0931\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 126s 402ms/step - loss: 0.0936\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 126s 403ms/step - loss: 0.0932\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 127s 406ms/step - loss: 0.0930\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 132s 423ms/step - loss: 0.0931\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 135s 430ms/step - loss: 0.0933\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 132s 421ms/step - loss: 0.0930\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 130s 417ms/step - loss: 0.0931\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 127s 405ms/step - loss: 0.0928\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 130s 416ms/step - loss: 0.0927\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 121s 388ms/step - loss: 0.0928\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 120s 382ms/step - loss: 0.0928\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 121s 387ms/step - loss: 0.0934\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 122s 391ms/step - loss: 0.0927\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 122s 391ms/step - loss: 0.0927\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 126s 401ms/step - loss: 0.0926\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 123s 392ms/step - loss: 0.0929\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 123s 394ms/step - loss: 0.0926\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 122s 389ms/step - loss: 0.0925\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 122s 391ms/step - loss: 0.0924\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 122s 388ms/step - loss: 0.0924\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 135s 430ms/step - loss: 0.0924\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 199s 637ms/step - loss: 0.0928\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 174s 557ms/step - loss: 0.0924\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 178s 567ms/step - loss: 0.0922\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 155s 495ms/step - loss: 0.0923\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 162s 519ms/step - loss: 0.0923\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 154s 492ms/step - loss: 0.0921\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 163s 521ms/step - loss: 0.0922\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 166s 531ms/step - loss: 0.0921\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 171s 548ms/step - loss: 0.0922\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 160s 511ms/step - loss: 0.0927\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 146s 467ms/step - loss: 0.0922\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 140s 447ms/step - loss: 0.0922\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 142s 452ms/step - loss: 0.0921\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 136s 436ms/step - loss: 0.0921\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 133s 426ms/step - loss: 0.0919\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 142s 452ms/step - loss: 0.0919\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 132s 420ms/step - loss: 0.0933\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 154s 492ms/step - loss: 0.0927\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 134s 430ms/step - loss: 0.0922\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 136s 435ms/step - loss: 0.0921\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 145s 464ms/step - loss: 0.0919\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 145s 464ms/step - loss: 0.0919\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 136s 433ms/step - loss: 0.0919\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 151s 481ms/step - loss: 0.0919\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 140s 449ms/step - loss: 0.0918\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 147s 469ms/step - loss: 0.0921\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 145s 464ms/step - loss: 0.0917\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 141s 451ms/step - loss: 0.0929\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 183s 584ms/step - loss: 0.0922\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 175s 560ms/step - loss: 0.0920\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 153s 489ms/step - loss: 0.0919\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 159s 509ms/step - loss: 0.0916\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 149s 476ms/step - loss: 0.0916\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 154s 491ms/step - loss: 0.0919\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 162s 517ms/step - loss: 0.0918\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 159s 509ms/step - loss: 0.0920\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 161s 514ms/step - loss: 0.0919\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 160s 512ms/step - loss: 0.0917\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 153s 490ms/step - loss: 0.0918\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 171s 546ms/step - loss: 0.0916\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 283s 905ms/step - loss: 0.0915\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 197s 631ms/step - loss: 0.0919\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 248s 794ms/step - loss: 0.0916\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 183s 585ms/step - loss: 0.0916\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 167s 534ms/step - loss: 0.0915\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 176s 561ms/step - loss: 0.0914\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 168s 536ms/step - loss: 0.0915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f728037dfd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train_pad, X_train_pad, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Masking(mask_value=0))\n",
    "model.add(layers.LSTM(20, activation=\"tanh\"))\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "model.add(LSTM(20, activation='tanh', return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm autoencoder recreate sequence\n",
    "from numpy import array\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n",
    "# define input sequence\n",
    "sequence = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(sequence)\n",
    "sequence = sequence.reshape((1, n_in, 1))\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(RepeatVector(n_in))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(sequence, sequence, epochs=300, verbose=0)\n",
    "#connect the encoder LSTM as the output layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "#plot_model(model, show_shapes=True, to_file='lstm_encoder.png')\n",
    "# get the feature vector for the input sequence\n",
    "#yhat = model.predict(sequence)\n",
    "#print(yhat.shape)\n",
    "#print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc150aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197eee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496343a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb935095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac6ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6653e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
